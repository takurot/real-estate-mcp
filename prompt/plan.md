## 実装計画（PR 単位）

目的: `evalGrowthRate.py` の品質向上と、Google Maps を用いた時系列・傾き可視化（期間・アルゴリズム可変）までを、小さくレビューしやすい PR に分割して実装する。

### 前提条件

- **実装環境**: Python 3.11 以上
- **方針**: 既存の `evalGrowthRate.py` を破壊的に変更せず、段階的に関数分割・引数化
- **出力構造**: `output/` 配下に階層化、地物は `data/boundaries.geojson`（市区町村境界; `properties.CityCode`）を想定
- **API 制約**: レート制限は実測ベースで調整（保守的に 1 req/sec 想定、並列化は 4 ～ 8 workers）
- **セキュリティ**: API キー・Google Maps キーは環境変数管理、`.gitignore` で保護

### データ構造定義（全 PR 共通）

#### `df_grouped` の列

| 列名           | 型    | 説明                              |
| -------------- | ----- | --------------------------------- |
| `CityCode`     | str   | 5 桁市区町村コード（例: "13101"） |
| `CityName`     | str   | 市区町村名（例: "千代田区"）      |
| `Year`         | int   | 年度（例: 2024）                  |
| `Price`        | float | 平均取引価格（万円）              |
| `PricePerUnit` | float | 平均坪単価（万円/坪）             |

#### GeoJSON `properties` 構造

```json
{
  "properties": {
    "CityCode": "13101",
    "CityName": "千代田区",
    "metrics": {
      "2018": { "Price": 5432.1, "PricePerUnit": 123.4 },
      "2019": { "Price": 5678.9, "PricePerUnit": 125.6 }
    },
    "slope_price": 123.45,
    "slope_ppu": 1.23
  }
}
```

---

### PR1: クリーニングと CLI 化（最小リファクタ）

- **目的**: 可読性と再現性を高める最小限の整備。**重大度: 高**のバグ修正を含む。
- **主な変更**
  - `main()` 導入、`argparse` による引数化（開始年・終了年・上位件数・対象都道府県・出力先・指標など）。
  - **傾き算出の是正**（重大度: 高）: `df_grouped`（市区町村 × 年で平均済み）で回帰を実行。
  - 変数名整理（`top_num` → `top_n`、`top_10_*` → `top_n_*`）。
  - 出力ディレクトリ `output/{pref}/plots`, `output/{pref}/tables` の作成。
  - フォントフォールバック設定（`['Hiragino Sans', 'Noto Sans CJK JP', 'MS Gothic', 'DejaVu Sans']`）。
- **ファイル**: `evalGrowthRate.py` のみ。
- **テスト/検証**:
  - 引数無しと有りで動作確認。
  - 出力先ディレクトリが自動作成されること。
  - 傾き計算が `df_grouped` を使用していることをコードレビューで確認。
  - 同一市区町村・同一年に複数行がある場合の動作確認（集約後は 1 行/年）。
- **完了条件**: 既存の PNG 出力が従来通り得られ、傾きランキングが正確。
- **リスク**: 軽微（既存ロジックに沿う）。傾き順位が変わる可能性（バグ修正のため意図通り）。

---

### PR2: ネットワーク堅牢化（Session/Timeout/Retry）

- **目的**: API 失敗に強い取得処理。**重大度: 中**の問題を解決。
- **主な変更**
  - `requests.Session()` 再利用、`timeout` 付与（10 ～ 30 秒）。
  - `urllib3.Retry` による 429/5xx に対する指数バックオフ（`max_retries=3`, `backoff_factor=1.0`, `status_forcelist=[429, 500, 502, 503, 504]`）。
  - 進捗バー（`tqdm`）と `logging` による INFO/DEBUG ログの導入。
  - エラーレスポンスの詳細ログ出力（ステータスコード、レスポンス本文の一部）。
- **ファイル**: `evalGrowthRate.py`。
- **テスト/検証**:
  - モックサーバ（`responses` ライブラリ）で 429/500/503 応答を返し、リトライ動作を確認。
  - タイムアウト発生時の例外ハンドリングと継続実行を確認。
  - 進捗バーが正しく表示されることを目視確認。
- **完了条件**: 一過性障害での再試行が機能し、ログで追跡可能。
- **リスク**: レート制限に配慮（バックオフ設定）。API 側の制限次第で調整が必要。

---

### PR3: データ整形と永続化（CSV/Parquet）

- **目的**: 再分析のための集約データを保存。**重大度: 中**の問題を解決。
- **主な変更**
  - `df_grouped` を `output/{pref}/tables/df_grouped.csv` に保存（列: `CityCode`, `CityName`, `Year`, `Price`, `PricePerUnit`）。
  - 全都道府県横断の結合テーブルも `output/all/df_grouped_all.csv` に保存。
  - 数値変換・欠損処理の明示化（`pd.to_numeric(..., errors='coerce')`）、最小年数フィルタ（期間内に観測 >= 2）。
  - オプションで Parquet 形式も保存（`pyarrow` または `fastparquet` 依存）。
  - メタデータファイル（`output/metadata.json`）に実行日時、API キー（マスク）、年度範囲、取得件数を記録。
- **ファイル**: `evalGrowthRate.py`。
- **テスト/検証**:
  - 出力 CSV の列名・dtype（`CityCode: str`, `Year: int`, `Price: float` 等）を検査。
  - サンプル県で行数が期待通りか確認（市区町村数 × 年数）。
  - 欠損値の扱いを確認（NaN 行の有無、フィルタ後の件数）。
- **完了条件**: 後続処理（GeoJSON 生成、再可視化）がファイルから再現可能。
- **リスク**: 保存サイズの増加（全県で数 MB ～数十 MB、Parquet で圧縮推奨）。

---

### PR4: パフォーマンス向上（並列化・簡易キャッシュ）

- **目的**: 取得時間の短縮と再実行の効率化。**重大度: 中**の問題を解決。
- **主な変更**
  - `ThreadPoolExecutor(max_workers=K)` で年度 × 都道府県の取得を並列化（K は引数化、デフォルト 4 ～ 8）。
  - `cache/{year}_{pref}.json` の簡易キャッシュを導入（存在時はスキップ、`--force-refresh` で無視）。
  - キャッシュファイルに取得日時とレスポンスヘッダ（Content-Length 等）を記録。
- **ファイル**: `evalGrowthRate.py`, `cache/`（新規ディレクトリ、`.gitignore` に追加）。
- **テスト/検証**:
  - 初回実行の所要時間を計測（目安: 逐次 ~8 分 → 並列 4 workers で ~2 分）。
  - 2 回目実行でキャッシュヒット率 100% を確認、所要時間 ~5 秒以内。
  - `--force-refresh` でキャッシュを無視して再取得されることを確認。
- **完了条件**: 所要時間が大幅改善し、キャッシュ機構が動作。
- **リスク**: API 規約に合わせ同時数を制限（レート制限超過に注意）。キャッシュの陳腐化（定期的にクリア推奨）。

**パフォーマンス指標（目安）**:

| 構成           | 実行時間（初回） | 実行時間（キャッシュ有） | 備考                |
| -------------- | ---------------- | ------------------------ | ------------------- |
| 逐次（現状）   | ~8 分            | N/A                      | 470 req × 1 sec/req |
| 並列 4 workers | ~2 分            | ~5 秒                    | API 負荷次第で調整  |
| 並列 8 workers | ~1 分            | ~5 秒                    | レート制限に注意    |

---

### PR5: 可視化の整備（PNG 出力の品質・一貫性）

- **目的**: 既存グラフの品質向上と再現性。
- **主な変更**
  - DPI・余白・凡例位置の統一、カラーパレットの固定。
  - フォントのフォールバック（`Hiragino Sans` → `Noto Sans CJK JP`）。
  - ランキング表（傾き上位/下位）を PNG/CSV で併走出力。
- **ファイル**: `evalGrowthRate.py`。
- **テスト/検証**: サンプル県で目視確認、欠損時の挙動確認。
- **完了条件**: 出力が判読しやすく統一。
- **リスク**: 画像点数増加。

---

### PR6: GeoJSON メトリクス生成（マップ用データ）

- **目的**: Google Maps 表示に必要なメトリクスを地物に付与。
- **主な変更**
  - `data/boundaries.geojson` を読み込み、`CityCode` で `df_grouped` をマージ。
  - `properties.metrics[year] = { Price, PricePerUnit }` を格納。
  - 任意で事前に `slope_price`, `slope_ppu` も付与。
  - 出力: `output/geo/geo_metrics.geojson`。
- **ファイル**: 新規 `scripts/generate_geojson.py`（または `evalGrowthRate.py` 内コマンド）。
- **テスト/検証**: ランダムに数件突合、欠損時のスキップ確認。
- **完了条件**: GeoJSON が 1 ファイルで可視化可能。
- **リスク**: コード体系の不一致（マッピング表で緩和）。

---

### PR7: Web マップ基盤（Google Maps + 年スライダー）

- **目的**: 地図上で年別値を確認できる最小構成を提供。
- **主な変更**
  - 静的 `web/index.html` を追加。Google Maps Data Layer で `geo_metrics.geojson` を描画。
  - 年スライダー・指標（Price/PricePerUnit）セレクタ・凡例・ツールチップ。
  - API キーの設定手順（ローカルのみ、キーは公開しない）。
- **ファイル**: `web/index.html`, `web/assets/*`。
- **テスト/検証**: ローカル開封で地図と塗りが表示されること。
- **完了条件**: スライダーで年を変えられる。
- **リスク**: キーの扱い（公開リポは使用しない）。

---

### PR8: 傾きの発散色コロプレス（期間・アルゴリズム可変）

- **目的**: 一目で増減の大きさを把握可能にする。
- **主な変更**
  - UI: 期間（from/to）、アルゴリズム選択（OLS/Theil–Sen/CAGR）、最小年数、指標切替。
  - JS: `slopeForFeature`（OLS/Theil–Sen/CAGR）と発散色スケール、95% 分位でドメイン設定。
  - 単位・凡例の動的表示（年率/値/年）。
- **ファイル**: `web/index.html`（JS 追記）。
- **テスト/検証**: 欠損や極端値で破綻しないことを確認。
- **完了条件**: 傾きの色分けが機能し、期間・手法で更新される。
- **リスク**: 計算コスト（市区町村数に応じて微小）。

---

### PR9: ドキュメント・パッケージング

- **目的**: 再現性と導入のしやすさを確保。
- **主な変更**
  - `requirements.txt` 作成（バージョン固定）:
    ```
    pandas>=2.0.0
    numpy>=1.24.0
    matplotlib>=3.7.0
    seaborn>=0.13.0
    requests>=2.31.0
    tqdm>=4.66.0
    python-dotenv>=1.0.0
    urllib3>=2.0.0
    ```
  - `.env.example` 追加:
    ```bash
    HUDOUSAN_API_KEY=your_api_key_here
    GOOGLE_MAPS_API_KEY=your_google_maps_key_here
    ```
  - `.gitignore` 更新（`.env`, `cache/`, `output/` を追加）。
  - `README.md` 更新（セクション追加）:
    - セットアップ手順（venv、依存インストール、`.env` 設定）
    - API キーの申請方法（国交省、Google Maps）
    - 実行例（最小、全県、特定県のみ）
    - 出力ディレクトリ構造
    - トラブルシューティング（タイムアウト、キャッシュクリア、文字化け）
    - データ利用規約（国交省 API、国土数値情報の出典明示）
    - 市区町村境界データの入手先（国土数値情報 URL）
- **ファイル**: `requirements.txt`, `.env.example`, `.gitignore`, `README.md`。
- **テスト/検証**:
  - クリーン環境（新規 venv）でセットアップ動作確認。
  - `pip install -r requirements.txt` でエラーが無いこと。
  - README の手順通りに実行し、出力が得られること。
- **完了条件**: 新規クローンで手順通りに再現可能。第三者がドキュメントのみでセットアップできる。
- **リスク**: なし。

---

### PR10: 解析品質向上（任意の拡張）

- **目的**: より頑健な分析と検証。テスト戦略を実装。
- **主な変更**
  - Python 側に Theil–Sen/CAGR の関数を実装（`analyze.py` または `evalGrowthRate.py` 内）し、CSV に傾き列を追加（バッチ算出）。
  - 単体テスト（`tests/test_analyze.py`）:
    - `compute_slope_xy` の端点テスト（1 年: `None`, 2 年: 正しい傾き、一定値: 傾き 0）
    - 欠損混入時の除外確認（`np.nan` を無視）
    - OLS/Theil–Sen/CAGR の比較（外れ値に対する頑健性）
    - 負値での CAGR: `None` を返す
  - 統合テスト（`tests/test_integration.py`）:
    - API モック（`responses` ライブラリ）で全フロー実行
    - キャッシュの読み書き
    - 出力ファイルの存在確認（PNG/CSV/GeoJSON）
  - エッジケーステスト:
    - 全年度欠損の市区町村: グレー表示
    - 極端な外れ値（価格 1 億超）: 95% 分位でクリップ
    - コード不一致: マッピング表での補完
  - CI（任意、GitHub Actions）で `pytest` + `flake8`/`black` の実行。
- **ファイル**: `tests/test_analyze.py`, `tests/test_integration.py`, `.github/workflows/ci.yml`（任意）。
- **テスト/検証**:
  - `pytest tests/` がグリーン。
  - カバレッジ確認（`pytest --cov`）で主要ロジックが 80% 以上。
  - 手動検証と整合（傾きの値が一致）。
- **完了条件**: テスト完備、回帰しづらい。CI でテストが自動実行（任意）。
- **リスク**: 実行時間（軽微、テストは数秒）。Theil–Sen は O(n²) だが市区町村単位なら問題なし。

---

## 実装順序とマージ方針

### 推奨順序

PR1 → PR2 → PR3 → PR4 → PR5 → PR6 → PR7 → PR8 → PR9 → PR10 の順で段階的に実装。

### マージ方針

- **粒度**: 各 PR は独立にレビュー可能な粒度に保つ（最大 300± 行程度目安）。
- **依存関係**:
  - PR1 ～ 5 はバックエンド（Python）、順次依存。
  - PR6 は PR3 に依存（CSV が必要）。
  - PR7 ～ 8 はフロントエンド、PR6 に依存（GeoJSON が必要）。
  - PR9 は独立（ドキュメント）、並行可能。
  - PR10 は独立（テスト）、並行可能。
- **レビュー観点**:
  - PR1: バグ修正の正確性、引数の妥当性
  - PR2: リトライロジックの堅牢性、ログの適切性
  - PR3: データスキーマの整合性、欠損処理
  - PR4: 並列化の安全性、キャッシュの正確性
  - PR5: グラフの可読性、DPI 統一
  - PR6: GeoJSON スキーマの正確性、コードマッピング
  - PR7 ～ 8: UI/UX、アクセシビリティ、API キーの扱い
  - PR9: ドキュメントの正確性、再現性
  - PR10: テストカバレッジ、エッジケース網羅
- **静的構成**: フロント（PR7–8）はサーバ不要の静的構成、デプロイ時はビルド不要（ホスティングのみ）。

### セキュリティチェックリスト（全 PR 共通）

- [ ] API キー・Google Maps キーがハードコードされていない
- [ ] `.env` が `.gitignore` に含まれている
- [ ] `.env.example` にプレースホルダーのみ記載
- [ ] ログ出力で API キーがマスクされている
- [ ] キャッシュファイルに機密情報が含まれていない

## 受け入れ基準（完成時）

### 機能要件

- コマンドラインで年範囲・上位件数・対象都道府県などを指定して取得・分析・PNG/CSV 出力が再現できる。
- GeoJSON を生成し、Web マップ上で年別表示と傾きの色分け（期間・手法可変）が動作する。
- README と `requirements.txt` の手順で第三者がセットアップ・再現可能。

### 非機能要件

- 全県取得が並列 4 workers で 2 分以内（キャッシュ有で 5 秒以内）。
- 単体テスト・統合テストが完備され、`pytest` がグリーン。
- 主要ロジックのテストカバレッジ 80% 以上。
- セキュリティチェックリスト完了。

### ドキュメント要件

- README に以下が含まれる:
  - セットアップ手順
  - API キー申請方法
  - 実行例（最小、全県、特定県）
  - 出力ディレクトリ構造
  - トラブルシューティング
  - データ利用規約・出典明示
- `.env.example` が用意されている。
- `requirements.txt` でバージョン固定。

---

## 残存リスク・今後の課題

### 残存リスク

- **API 仕様の未確認**: レート制限が未公開の場合、実測ベースで調整が必要。
- **市区町村合併**: 年度横断時のコード変更に未対応（マッピング表で緩和）。
- **メモリ使用量**: 全県 × 10 年のデータセットで数百 MB のメモリ使用（実測要）。
- **Google Maps API キー**: 静的 HTML での露出（ローカル限定または認証強化）。

### 今後の課題（スコープ外）

- 市区町村合併履歴テーブルの整備（コード変換の自動化）。
- サーバサイドレンダリング（API キー保護）。
- データベース化（SQLite/PostgreSQL）による大規模データ管理。
- より高度な統計分析（季節調整、自己相関、クラスタリング）。
- CI/CD パイプライン（自動デプロイ、データ更新）。

### MCP サーバー：API キャッシュ方針

- **背景**: MLIT API はサブスクリプションキーでアクセスが制御され、レート制限も明示されていないため、再取得の削減とスロットリング緩和を目的に MCP サーバー側でキャッシュを持つ。
- **可否判断**: API 操作説明ではキャッシュ禁止が明記されておらず、取得データの加工・再利用も利用約款に従えば許容範囲。応答を改ざんせず TTL を設定すればコンプライアンス上問題なし。
- **実装案**:
  - In-memory LRU（例: 256 エントリ）＋ TTL（例: 6 時間）で JSON 応答をキャッシュ。キーは `endpoint + sorted(params)` をハッシュ化。
  - GeoJSON/MVT のような大容量レスポンスは一時ファイルに書き出し、MCP の `resource://` スキームで再利用。ハッシュに基づきファイル名を決定し、最終アクセス時刻でクリーンアップ。
  - `force_refresh` フラグを各 MCP ツールに追加し、キャッシュをバイパス可能にする。
  - レート制限緩和のため、キャッシュヒット時は HTTP 呼び出しをスキップしつつログに「HIT/ MISS」を記録し、観測データとして収集。
- **実装タスク**:
  1. `CacheStore` 抽象クラスを定義（`get`, `set`, `purge_expired`）。メモリ実装とファイル実装を用意。
  2. 各ツール呼び出し前後でキャッシュを参照・更新。レスポンスメタデータ（`fetched_at`, `ttl_seconds`, `source_etag`）を付与。
  3. 設定値（TTL、最大エントリ、ディスク保存先）を `.env` / MCP 設定で外部化。
  4. `force_refresh` や TTL 失効時の挙動を統合テストに追加し、キャッシュバイパスが想定通り動作するか検証。
